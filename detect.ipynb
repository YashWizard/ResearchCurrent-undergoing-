{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb27f819-33fd-47fc-8bc8-5c0b204644eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def detect_teeth(image_path):\n",
    "    # Read the image\n",
    "    img = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # Use adaptive thresholding to create a binary image\n",
    "    thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "\n",
    "    # Find contours in the thresholded image\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Filter contours based on area to remove small noise\n",
    "    min_area = 100  # Adjust this value based on your image\n",
    "    filtered_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > min_area]\n",
    "\n",
    "    # Draw the contours on the original image\n",
    "    result = img.copy()\n",
    "    cv2.drawContours(result, filtered_contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the result\n",
    "    cv2.imshow('Detected Teeth', result)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Use the function with your image\n",
    "detect_teeth('simple.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18ab27ab-fe1c-4cea-bf2f-10dd1f2e97cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rough detection WORKING!!!\n",
    "\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def detect_landmarks(image_path):\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Preprocess: Gaussian blur and adaptive thresholding\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "\n",
    "    # Find contours: Detect tooth contours\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Filter contours: Keep only the largest one (tooth)\n",
    "    min_area = 100  # Adjust this based on the image\n",
    "    largest_contour = max([cnt for cnt in contours if cv2.contourArea(cnt) > min_area], key=cv2.contourArea)\n",
    "\n",
    "    # Approximate Landmarks\n",
    "    leftmost = tuple(largest_contour[largest_contour[:,:,0].argmin()][0])\n",
    "    rightmost = tuple(largest_contour[largest_contour[:,:,0].argmax()][0])\n",
    "    bottommost = tuple(largest_contour[largest_contour[:,:,1].argmax()][0])\n",
    "\n",
    "    #Estimate landmarks\n",
    "    cej_approx = ((leftmost[0] + rightmost[0]) // 2, (leftmost[1] + rightmost[1]) // 2)\n",
    "    root_apex = bottommost\n",
    "\n",
    "    #Draw the landmarks\n",
    "    cv2.circle(img, cej_approx, 7, (0, 0, 255), -1) #red\n",
    "    cv2.circle(img, root_apex, 7, (255, 0, 0), -1) #blue\n",
    "    cv2.putText(img, \"CEJ\", (cej_approx[0] - 20, cej_approx[1] - 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "    cv2.putText(img, \"Apex\", (root_apex[0] - 20, root_apex[1] + 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "\n",
    "    #Show image for measurement\n",
    "    cv2.imshow('Landmark Detection', img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "detect_landmarks('simple.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ec0e370-99e5-48db-927b-d9f73765c861",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CEJ DETECTION DONE FOR ATLEAST 1 IMAGE :)\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def getCEJPoint(image_path):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        print(f\"Error: Could not open image at {image_path}\")\n",
    "        return\n",
    "    #Preprocessing\n",
    "    blurred = cv2.GaussianBlur(img, (7, 7), 0)\n",
    "    thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "    if np.mean(thresh) < 127:\n",
    "        thresh = cv2.bitwise_not(thresh)\n",
    "\n",
    "    #Contour time\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours:\n",
    "        print(\"Error: No contours found.\")\n",
    "        return\n",
    "\n",
    "    #Get the landmarks\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    leftmost = tuple(largest_contour[largest_contour[:,:,0].argmin()][0])\n",
    "    rightmost = tuple(largest_contour[largest_contour[:,:,0].argmax()][0])\n",
    "\n",
    "    approximateCeJ = ((leftmost[0] + rightmost[0]) // 2, (leftmost[1] + rightmost[1]) // 2)\n",
    "    #Visualization time\n",
    "\n",
    "    img_color = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    cv2.circle(img_color, approximateCeJ, 5, (0, 0, 255), -1)\n",
    "\n",
    "    #Putting in some extra help here\n",
    "    cv2.putText(img_color, \"red=CEJ\", (approximateCeJ[0] - 20, approximateCeJ[1] - 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "    #Finishing visualization with the showing the image\n",
    "    cv2.imshow(\"Measurements\", img_color)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "if __name__ == \"__main__\":\n",
    "    image_file = \"simple.png\"\n",
    "    getCEJPoint(image_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7e1002d-eb6d-41af-a596-9c9c289f7399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def theLastWhite(image_path):\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        print(f\"Error: Could not open image at {image_path}\")\n",
    "        return\n",
    "\n",
    "    # Guassian blue to preprocess the image\n",
    "    blurred = cv2.GaussianBlur(img, (7, 7), 0)\n",
    "    thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "    # Find \"white area\"\n",
    "    if np.mean(thresh) < 127:\n",
    "        thresh = cv2.bitwise_not(thresh)\n",
    "\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours:\n",
    "        print(\"Error: No contours found.\")\n",
    "        return\n",
    "        \n",
    "    #Get that image in the contours and return\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    bottommost = tuple(largest_contour[largest_contour[:,:,1].argmax()][0])\n",
    "\n",
    "    img_color = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    cv2.circle(img_color, bottommost, 5, (0, 0, 255), -1)\n",
    "    cv2.putText(img_color, \"Bottom Point\", (bottommost[0] - 20, bottommost[1] - 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Measurements\", img_color)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "if __name__ == \"__main__\":\n",
    "    image_file = \"Picture 50.png\"\n",
    "    theLastWhite(image_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7644d084-05ff-4cbd-8594-dd1059a7c527",
   "metadata": {},
   "outputs": [],
   "source": [
    "#most perfect :)\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def detect_landmarks(image_path):\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Preprocess: Gaussian blur and adaptive thresholding\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "\n",
    "    # Find contours: Detect tooth contours\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Filter contours: Keep only the largest one (tooth)\n",
    "    min_area = 100  # Adjust this based on the image\n",
    "    largest_contour = max([cnt for cnt in contours if cv2.contourArea(cnt) > min_area], key=cv2.contourArea)\n",
    "\n",
    "    # Approximate Landmarks\n",
    "    leftmost = tuple(largest_contour[largest_contour[:,:,0].argmin()][0])\n",
    "    rightmost = tuple(largest_contour[largest_contour[:,:,0].argmax()][0])\n",
    "    bottommost = tuple(largest_contour[largest_contour[:,:,1].argmax()][0])\n",
    "\n",
    "    #Estimate landmarks\n",
    "    cej_approx = ((leftmost[0] + rightmost[0]) // 2, (leftmost[1] + rightmost[1]) // 2)\n",
    "    root_apex = bottommost\n",
    "\n",
    "    # Calculate pixel distance\n",
    "    distance = np.sqrt((cej_approx[0] - root_apex[0])**2 + (cej_approx[1] - root_apex[1])**2)\n",
    "\n",
    "    #Draw the landmarks\n",
    "    cv2.circle(img, cej_approx, 7, (0, 0, 255), -1) #red\n",
    "    cv2.circle(img, root_apex, 7, (255, 0, 0), -1) #blue\n",
    "    cv2.line(img, cej_approx, root_apex, (0, 255, 0), 2) #green line\n",
    "    cv2.putText(img, \"CEJ\", (cej_approx[0] - 20, cej_approx[1] - 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "    cv2.putText(img, \"Apex\", (root_apex[0] - 20, root_apex[1] + 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "    cv2.putText(img, f\"Distance: {distance:.2f} pixels\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "    #Show image for measurement\n",
    "    cv2.imshow('Landmark Detection', img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "detect_landmarks('simple.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "756f02ce-a08d-4804-94a7-8cabfa8a6bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Failed to load image at 'image 7.jpg'. Possible causes:\n",
      "- File doesn't exist at specified path\n",
      "- File is corrupted\n",
      "- Invalid file format\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m     exit()\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Verify image dimensions\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal image size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Resize only if original image is not empty\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "# Load image in grayscale\n",
    "img_path = \"image 7.jpg\"\n",
    "img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Check if image loaded properly\n",
    "if img is None:\n",
    "    print(f\"Error: Failed to load image at '{img_path}'. Possible causes:\")\n",
    "    print(\"- File doesn't exist at specified path\")\n",
    "    print(\"- File is corrupted\")\n",
    "    print(\"- Invalid file format\")\n",
    "    exit()\n",
    "\n",
    "# Verify image dimensions\n",
    "print(f\"Original image size: {img.shape}\")\n",
    "\n",
    "# Resize only if original image is not empty\n",
    "try:\n",
    "    img_resized = cv2.resize(img, (256, 512))\n",
    "except cv2.error as e:\n",
    "    print(f\"Resize failed: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Continue with processing\n",
    "height, width = img_resized.shape\n",
    "gum_line_y = []\n",
    "\n",
    "for x in range(width):\n",
    "    column = img_resized[:, x]\n",
    "    smoothed = gaussian_filter1d(column, sigma=2)\n",
    "    gradient = np.gradient(smoothed)\n",
    "    peak_index = np.argmax(gradient)\n",
    "    gum_line_y.append(peak_index)\n",
    "\n",
    "gum_line_y = gaussian_filter1d(gum_line_y, sigma=5)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Extracted Gum Line\")\n",
    "plt.plot(gum_line_y, color='red', linewidth=2)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8855129c-f3b1-47fb-937a-0f33f13836ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
